{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for classification, without and with kernels\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVMs) for image classification. We are going to use the famous MNIST dataset, that is a dataset of handwritten digits. We get the data from mldata.org, that is a public repository for machine learning data.\n",
    "\n",
    "The dataset consists of 70,000 images of handwritten digits (i.e., 0, 1, ... 9). Each image is 28 pixels by 28 pixels and we can think of it as a vector of 28x28 = 784 numbers. Each number is an integer between 0 and 255. For each image we have the corresponding label (i.e., 0, 1, ..., 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#for display purposes\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator\n",
    "ID = 2026826\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the dataset. 'data' contains the input, 'target' contains the label. We normalize the data by dividing each value by 255 so that each value is in [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STUDENT NOTES:\n",
    "It has been added as additional parameter *as_frame=False* into the *fetch_openml* function in order to deal with *numpy.ndarray* instead of *pandas.DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the MNIST dataset and let's normalize the features so that each value is in [0,1]\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "# rescale the data\n",
    "X, y = mnist.data / 255., mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. We keep 500 samples in the training set. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens.\n",
    "\n",
    "**IMPORTANT**: if you cannot run the SVM with 500 samples or 1000 samples (see below), try with a smaller number of samples (e.g. 200 here and 400 below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in training dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([51, 64, 40, 52, 51, 45, 46, 44, 49, 58], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 500\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "print(\"Labels and frequencies in training dataset: \")\n",
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STUDENT NOTES\n",
    "In the following block checks if there are at least 10 elements for each label. If not, it will be added permutations until the condition is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([51, 64, 40, 52, 51, 45, 46, 44, 49, 58], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, labels_qty = np.unique(y_train, return_counts = True)\n",
    "\n",
    "while(not(np.all(labels_qty >= 10))):\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "\n",
    "    m_training = 500\n",
    "\n",
    "    X_train, X_test = X[:m_training], X[m_training:]\n",
    "    y_train, y_test = y[:m_training], y[m_training:]\n",
    "    \n",
    "    labels, labels_qty = np.unique(y_train, return_counts = True)\n",
    " \n",
    "np.unique(y_train, return_counts = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide a function to print an image in a dataset, the corresponding true label, and the index of the image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a digit and printing the corresponding labe\n",
    "def plot_digit(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %s\" % labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's print the 100-th image in X_train and the 40,000-th image in X_test and their true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_digit(X_train,y_train,100)\n",
    "plot_digit(X_test,y_test,40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Run SVM with cross validation to pick a kernel and values of parameters. Use a 5-fold cross-validation to pick the best kernel and choice of parameters. We provide some potential choice for parameters, but change the grid if needed (e.g., it takes too long). For the SVM for classification use SVC from sklearn.svm; for the grid search we suggest you use GridSearchCV from sklearn.model_selection, but you can implement your own cross-validation for model selection if you prefer.\n",
    "\n",
    "Print the best parameters used as well as the score obtained by the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 1}\n",
      "Score with best parameters:\n",
      "0.852\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1        2\n",
       "C      1.000  10.000  100.000\n",
       "score  0.852   0.852    0.852"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 1, 'gamma': 0.1}\n",
      "Score with best parameters:\n",
      "0.86\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2       3      4      5       6       7       8\n",
       "C      1.00  1.00  1.00  10.000  10.00  10.00  100.00  100.00  100.00\n",
       "gamma  0.01  0.10  1.00   0.010   0.10   1.00    0.01    0.10    1.00\n",
       "score  0.83  0.86  0.86   0.858   0.86   0.86    0.86    0.86    0.86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR rbf KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.8880000000000001\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2       3       4       5        6        7        8\n",
       "C      1.000  1.000  1.000  10.000  10.000  10.000  100.000  100.000  100.000\n",
       "gamma  0.010  0.100  1.000   0.010   0.100   1.000    0.010    0.100    1.000\n",
       "score  0.862  0.546  0.128   0.888   0.592   0.128    0.888    0.592    0.128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "\n",
    "#find best model uusing 5-fold CV \n",
    "#and train it using all the training data\n",
    "\n",
    "# ADD CODE\n",
    "linear_kernel = GridSearchCV(linear_SVM, parameters)\n",
    "\n",
    "linear_kernel.fit(X_train, y_train)\n",
    "\n",
    "print ('RESULTS FOR LINEAR KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD CODE\n",
    "print(linear_kernel.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD CODE\n",
    "print(linear_kernel.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD CODE\n",
    "#print(\"Mean test scores: \", linear_kernel.cv_results_['mean_test_score'])\n",
    "params = linear_kernel.cv_results_['params']\n",
    "scores = linear_kernel.cv_results_['mean_test_score']\n",
    "results = [{'C' : value['C'], 'score' : scores[index]} for index, value in enumerate(params)]\n",
    "display(pandas.DataFrame(results).T)\n",
    "\n",
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "poly2_SVM = SVC(kernel='poly',degree=2)\n",
    "\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR POLYNOMIAL KERNEL WITH DEGREE=2\n",
    "poly2_kernel = GridSearchCV(poly2_SVM, parameters)\n",
    "\n",
    "poly2_kernel.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR POLY DEGREE=2 KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD CODE\n",
    "print(poly2_kernel.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD CODE\n",
    "print(poly2_kernel.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD CODE\n",
    "#print(\"Mean test scores: \", poly2_kernel.cv_results_['mean_test_score'])\n",
    "params = poly2_kernel.cv_results_['params']\n",
    "scores = poly2_kernel.cv_results_['mean_test_score']\n",
    "results = [{'C' : value['C'], 'gamma' : value['gamma'], 'score' : scores[index]} for index, value in enumerate(params)]\n",
    "display(pandas.DataFrame(results).T)\n",
    "\n",
    "# parameters for rbf SVM\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR RBF KERNEL\n",
    "\n",
    "rbf_kernel = GridSearchCV(rbf_SVM, parameters)\n",
    "\n",
    "rbf_kernel.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR rbf KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD CODE\n",
    "print(rbf_kernel.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD CODE\n",
    "print(rbf_kernel.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD CODE\n",
    "#print(\"Mean test scores: \", rbf_kernel.cv_results_['mean_test_score'])\n",
    "params = rbf_kernel.cv_results_['params']\n",
    "scores = rbf_kernel.cv_results_['mean_test_score']\n",
    "results = [{'C' : value['C'], 'gamma' : value['gamma'], 'score' : scores[index]} for index, value in enumerate(params)]\n",
    "display(pandas.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "For the \"best\" SVM kernel and choice of parameters from above, train the model on the entire training set and measure the training error. Also make predictions on the test set and measure the test error. Print the training and the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM chosen: kernel=rbf, C=10, gamma=0.01\n",
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.106863\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "scores_SVM = [linear_kernel.best_score_, poly2_kernel.best_score_, rbf_kernel.best_score_]\n",
    "kernels_SVM = [linear_kernel, poly2_kernel, rbf_kernel]\n",
    "\n",
    "best = np.argmax(scores_SVM)\n",
    "params = kernels_SVM[best].best_estimator_.get_params()\n",
    "print(\"Best SVM chosen: \" +\n",
    "      \"kernel=\" + str(params['kernel']) + \n",
    "      \", C=\" + str(params['C']) +\n",
    "      \", gamma=\" + str(params[\"gamma\"]))\n",
    "\n",
    "best_SVM = kernels_SVM[best].best_estimator_ # ADD CODE\n",
    "\n",
    "# fit the model on the entire training set\n",
    "# ADD CODE\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "#get the training and test error\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use logistic regression for comparison\n",
    "\n",
    "## TO DO 3\n",
    "\n",
    "Just for comparison let's also use logistic regression, first with the default values of the parameter for regularization and then with cross-validation to fix the value of the parameter. For cross validation, use 5-fold cross validation and the default values of the regularization parameters for the function linear_model.LogisticRegressionCV(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STUDENT NOTES\n",
    "For the regular LR and for the LR with CV is set *max_iter=1000* to don't display the warning messagges thrown by the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Logistic Regression\n",
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.148806\n",
      "\n",
      "LR after 5-fold Cross Validation\n",
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.155180\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LogisticRegression(max_iter=1000)\n",
    "# fit the model on the training data\n",
    "# ADD CODE\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#compute training and test error for model above\n",
    "training_error = 1 - lr.score(X_train, y_train) # COMPLETE\n",
    "test_error = 1 - lr.score(X_test, y_test) # COMPLETE\n",
    "print (\"Regular Logistic Regression\")\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)\n",
    "\n",
    "#logistic regression with 5-fold CV: you can use use linear_model.LogisticRegressionCV\n",
    "# use 5-fold CV to find the best choice of the parameter, than train\n",
    "# the model on the entire training set\n",
    "lr_cv = linear_model.LogisticRegressionCV(cv=5, max_iter=1000).fit(X_train, y_train) # COMPLETE\n",
    "training_error_cv = 1 - lr_cv.score(X_train, y_train) # COMPLETE\n",
    "test_error_cv = 1 - lr_cv.score(X_test, y_test) # COMPLETE\n",
    "\n",
    "print (\"\\nLR after 5-fold Cross Validation\")\n",
    "print (\"Best logistic regression training error: %f\" % training_error_cv)\n",
    "print (\"Best logistic regression test error: %f\" % test_error_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C obtained:  10000.0 \t[due to the default settings is the same for each class]\n"
     ]
    }
   ],
   "source": [
    "#line added to compare the regular LR with the LR trained with CV\n",
    "print(\"Best C obtained: \", lr_cv.C_[0], \"\\t[due to the default settings is the same for each class]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4 \n",
    "Compare and comment the results from SVM and logistic regression.\n",
    "\n",
    "#### ANSWER\n",
    "The SVM has good results with all the trained kernels, in fact the lowest score is around the 85.2% and it's reached by the linear kernel.<br>\n",
    "The **best results** is obtained by the non-linear *RBF kernel* with *C=10* and *gamma=0.01* and a **score of 88.8%**.<br>\n",
    "If we compare the parameters tested during the cross validation we can observe that it has been chosen, among the set values:\n",
    "1. **the middle value for C**, this means that the CV has obtain the best results by giving an \"equal importance\" among the complexity (the regularization) of the model and the empirical risk;\n",
    "2. **the lowest value for gamma**, this implies that the CV has detected an influence among far samples in the training set** \n",
    "\n",
    "The regular LR and the LR obtained with the CV (LR and LR_CV from now) have obtained training error equals to zero, this means that the training set is linearly separable. Also, we can observe that both test errors are quite similiar to the best test error (*1-score*) obtained with the SVM trained with a linear kernel (they are all around 15%). This is expected because Logistic Regression is applied by using a linear model and, as the SVM with linear kernel, it's trying to build an halfspace that divides the samples in the dataset.\n",
    "Another observation is that the LR have the regularization parameter *C=1*; instead the LR_CV has found out *C=10000* as the best regularization parameter, this is like not considering the hypothesis complexity for training the final model.\n",
    "\n",
    "Even if the data are linearly separable, the **best result** is obtained by the **SVM model with RBF kernel**, that is a non linear kernel, with a **test error of 10.7%** (against the 14.9% of LR and 15.5% of LR_CV).<br>\n",
    "**Therefore the non linear model (thanks to the kernel trick) is the one that best represents the real world.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Write the code that finds and plots a digit that is missclassified by logistic regression (optimized for the regularization parameter) and correctly classified by the \"best\" SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOEElEQVR4nO3dfYxUZZbH8d8RQY2gAWlZ4hCZBRPX+MKMLYpuJpBBgojBiRkdjIhi7PlD4xAnKFGS0SiJbgQyCRsSWHFgg05GGQIJZhcD+EJMRhtFwCW7voRlGDtQROM4asICZ//o62439n2qqXvrpTnfT9KpqnvqqXty4de3qp6qfszdBeD0d0azGwDQGIQdCIKwA0EQdiAIwg4EcWYjdzZy5EgfO3ZsI3cJhLJ//34dOXLE+qoVCruZTZf0W0mDJP2Luz+Tuv/YsWPV2dlZZJcAEtrb23NrNT+NN7NBkv5Z0k2SLpM028wuq/XxANRXkdfsEyV97O6fuvtRSb+XNKuctgCUrUjYL5L05x63D2bbejGzDjPrNLPOSqVSYHcAiigS9r7eBPjeZ2/dfaW7t7t7e1tbW4HdASiiSNgPShrT4/YPJH1WrB0A9VIk7O9KusTMfmhmQyT9QtKmctoCULaap97c/ZiZPSjp39U99bba3T8srTMApSo0z+7ur0p6taReANQRH5cFgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgiEKruKL1HT9+PFl/8sknk/Vnn302WT969GiyPn78+Nza448/nhx79913J+tnnMG56lQUCruZ7Zf0laTjko65e3sZTQEoXxln9inufqSExwFQRzwPAoIoGnaXtMXMdppZR193MLMOM+s0s85KpVJwdwBqVTTsN7j7jyXdJOkBM/vJyXdw95Xu3u7u7W1tbQV3B6BWhcLu7p9ll4clbZA0sYymAJSv5rCb2blmNuy765KmSdpbVmMAylXk3fhRkjaY2XeP86K7/1spXaE0S5YsSdaffvrpQo9/8cUXJ+uDBw/Orc2bNy859oorrkjWr7766mQdvdUcdnf/VNJVJfYCoI6YegOCIOxAEIQdCIKwA0EQdiAIvuI6ALzxxhvJ+uLFi3Nrb7/9dnLssGHDkvWHHnooWb/tttuS9Z07d+bW7r///uTYBQsWJOvbtm1L1tEbZ3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJ59hawZ8+eZP3mm29O1i+44ILc2iOPPJIcO3Xq1GT9+uuvT9aPHTuWrN97773JesrDDz9c81h8H2d2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCefYW8MknnyTrX3/9dbK+YsWK3NqcOXNq6qm/qi2r/MEHH+TW7rnnnuTYGTNm1NIScnBmB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgmGdvAWee2bx/hmrfR582bVqyvn379mT9mmuuya0tW7YsOfaMMzgXlanq0TSz1WZ22Mz29tg2wsxeM7OPssvh9W0TQFH9+dX5O0nTT9q2UNJWd79E0tbsNoAWVjXs7v6mpM9P2jxL0prs+hpJt5bbFoCy1fqiaJS7d0lSdnlh3h3NrMPMOs2ss1Kp1Lg7AEXV/R0Qd1/p7u3u3t7W1lbv3QHIUWvYD5nZaEnKLg+X1xKAeqg17Jskzc2uz5W0sZx2ANRL1QleM3tJ0mRJI83soKTfSHpG0h/M7D5JByT9vJ5Nnu5mzpyZrF955ZXJ+qJFi3JrQ4YMSY7dvHlzsv76668n65MmTUrW165dm1s7//zzk2NRrqphd/fZOaWfltwLgDriI0pAEIQdCIKwA0EQdiAIwg4EwVdcB4AtW7Yk69Onn/w9pf83e3beZEr/VJseW7x4cbI+fvz4QvtHeTizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQzLMPAKNGjUrWn3vuudzajTfeWGjf1b5eO2XKlEKPj8bhzA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDPfhr48ssv6/bYb731VrJ+yy23JOsvvPBCbm3kyJE19YTacGYHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSCYZz8NvPPOO7m1QYMGJcfu2LEjWa/2N+ufeuqpZP2uu+7Krb344ovJsSNGjEjWcWqqntnNbLWZHTazvT22PWFmfzGzXdnPjPq2CaCo/jyN/52kvpYcWebuE7KfV8ttC0DZqobd3d+U9HkDegFQR0XeoHvQzHZnT/OH593JzDrMrNPMOiuVSoHdASii1rCvkDRO0gRJXZKW5N3R3Ve6e7u7t7e1tdW4OwBF1RR2dz/k7sfd/YSkVZImltsWgLLVFHYzG93j5s8k7c27L4DWUHWe3cxekjRZ0kgzOyjpN5Imm9kESS5pv6Rf1q9FnDhxIln/4osvcmvXXXddcuy1115bqF7t78qn1oefP39+cuzy5cuT9fPOOy9ZR29Vw+7uff1rPV+HXgDUER+XBYIg7EAQhB0IgrADQRB2IAi+4joAbNy4MVlftWpVbm3p0qVlt9PLrFmzkvVt27bl1qZOnZocO3PmzGT99ttvT9bRG2d2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCefYBoMiSzFOmTCmxk1OX+optR0dHcuyCBQuS9WrLRZ9zzjnJejSc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZB4D3338/WU/9uefLL7+87HZKs2jRomR93bp1yfqGDRuS9TvvvPOUezqdcWYHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSCYZx8ADhw4kKxPmjQptzZo0KCy2ynNiBEjkvVHH300WX/llVeSdebZe6t6ZjezMWa23cz2mdmHZvarbPsIM3vNzD7KLofXv10AterP0/hjkn7t7v8g6TpJD5jZZZIWStrq7pdI2prdBtCiqobd3bvc/b3s+leS9km6SNIsSWuyu62RdGudegRQglN6g87Mxkr6kaQ/SRrl7l1S9y8ESRfmjOkws04z66xUKgXbBVCrfofdzIZKWi9pvrv/tb/j3H2lu7e7e3tbW1stPQIoQb/CbmaD1R30de7+x2zzITMbndVHSzpcnxYBlKHq1JuZmaTnJe1z957r/26SNFfSM9llel1h1Kz7nyCeSy+9NFl/+eWXG9TJ6aE/8+w3SJojaY+Z7cq2PabukP/BzO6TdEDSz+vSIYBSVA27u++QlHdq+Wm57QCoFz4uCwRB2IEgCDsQBGEHgiDsQBB8xXUAqDbfvGnTptzat99+mxzbyssaL1++PFmvdlzQG2d2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCefYB4I477kjW169fn1ubOXNmcmy1P7c8bty4ZL2ab775JrdW7U9Bn3322cn60qVLk3X0xpkdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Jgnn0AuOqqq5L13bt359aWLVuWHLt58+ZkvaurK1kfPXp0sp4yefLkZH3evHnJ+tChQ2ved0Sc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgiP6szz5G0lpJfyfphKSV7v5bM3tC0v2SKtldH3P3V+vVKPKdddZZubWFCxc2sBO0sv58qOaYpF+7+3tmNkzSTjN7Lastc/fn6tcegLL0Z332Lkld2fWvzGyfpIvq3RiAcp3Sa3YzGyvpR5L+lG160Mx2m9lqMxueM6bDzDrNrLNSqfR1FwAN0O+wm9lQSeslzXf3v0paIWmcpAnqPvMv6Wucu69093Z3b29rayveMYCa9CvsZjZY3UFf5+5/lCR3P+Tux939hKRVkibWr00ARVUNu5mZpOcl7XP3pT229/y6088k7S2/PQBl6c+78TdImiNpj5ntyrY9Jmm2mU2Q5JL2S/plHfoDUJL+vBu/Q5L1UWJOHRhA+AQdEARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCHP3xu3MrCLpv3tsGinpSMMaODWt2lur9iXRW63K7O1id+/z7781NOzf27lZp7u3N62BhFbtrVX7kuitVo3qjafxQBCEHQii2WFf2eT9p7Rqb63al0RvtWpIb019zQ6gcZp9ZgfQIIQdCKIpYTez6Wb2n2b2sZm11JrCZrbfzPaY2S4z62xyL6vN7LCZ7e2xbYSZvWZmH2WXfa6x16TenjCzv2THbpeZzWhSb2PMbLuZ7TOzD83sV9n2ph67RF8NOW4Nf81uZoMk/ZekGyUdlPSupNnu/h8NbSSHme2X1O7uTf8Ahpn9RNLfJK1198uzbf8k6XN3fyb7RTnc3R9tkd6ekPS3Zi/jna1WNLrnMuOSbpV0j5p47BJ93a4GHLdmnNknSvrY3T9196OSfi9pVhP6aHnu/qakz0/aPEvSmuz6GnX/Z2m4nN5agrt3uft72fWvJH23zHhTj12ir4ZoRtgvkvTnHrcPqrXWe3dJW8xsp5l1NLuZPoxy9y6p+z+PpAub3M/Jqi7j3UgnLTPeMseuluXPi2pG2PtaSqqV5v9ucPcfS7pJ0gPZ01X0T7+W8W6UPpYZbwm1Ln9eVDPCflDSmB63fyDpsyb00Sd3/yy7PCxpg1pvKepD362gm10ebnI//6eVlvHua5lxtcCxa+by580I+7uSLjGzH5rZEEm/kLSpCX18j5mdm71xIjM7V9I0td5S1Jskzc2uz5W0sYm99NIqy3jnLTOuJh+7pi9/7u4N/5E0Q93vyH8i6fFm9JDT199L+iD7+bDZvUl6Sd1P6/5H3c+I7pN0gaStkj7KLke0UG//KmmPpN3qDtboJvX2j+p+abhb0q7sZ0azj12ir4YcNz4uCwTBJ+iAIAg7EARhB4Ig7EAQhB0IgrADQRB2IIj/BR+3Cqzxzzg2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 5\n"
     ]
    }
   ],
   "source": [
    "# ADD CODE\n",
    "\n",
    "svm_labels = best_SVM.predict(X_test)\n",
    "lr_cv_labels = lr_cv.predict(X_test)\n",
    "for index, value in enumerate(y_test):\n",
    "    if (value != lr_cv_labels[index]) and (value == svm_labels[index]):\n",
    "        plot_digit(X_test, svm_labels, index)\n",
    "        plot_digit(X_test, lr_cv_labels, index)\n",
    "        break        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using 1000 data points for training. \n",
    "\n",
    "## TO DO 6\n",
    "Repeat the entire analysis above using 1000 samples. Of course you can copy the code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in training dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([100, 134,  98, 100,  76,  84,  95, 116, 112,  85], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 1000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "print(\"Labels and frequencies in training dataset: \")\n",
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STUDENT NOTES\n",
    "In the following block checks if there are at least 10 elements for each label. If not, it will be added permutations until the condition is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([100, 134,  98, 100,  76,  84,  95, 116, 112,  85], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, labels_qty = np.unique(y_train, return_counts = True)\n",
    "\n",
    "\n",
    "while(not(np.all(labels_qty >= 10))):\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "\n",
    "    m_training = 1000\n",
    "\n",
    "    X_train, X_test = X[:m_training], X[m_training:]\n",
    "    y_train, y_test = y[:m_training], y[m_training:]\n",
    "    \n",
    "    labels, labels_qty = np.unique(y_train, return_counts = True)\n",
    " \n",
    "np.unique(y_train, return_counts = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Cross Validation\n",
    "Run SVM with 5-fold cross validation to pick a kernel and values of parameters.\n",
    "\n",
    "As before, it's trained and chosen among the following parameters:\n",
    "1. **kernel** = [linear , polynomial with degree 2 , rbf]\n",
    "2. **C** = [1, 10, 100]\n",
    "3. **gamma** = [1, 0.1, 0.01] *(only for polynomial and rbf kernels)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 1}\n",
      "Score with best parameters:\n",
      "0.868\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1        2\n",
       "C      1.000  10.000  100.000\n",
       "score  0.868   0.868    0.868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 1, 'gamma': 0.1}\n",
      "Score with best parameters:\n",
      "0.884\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2       3       4       5        6        7        8\n",
       "C      1.000  1.000  1.000  10.000  10.000  10.000  100.000  100.000  100.000\n",
       "gamma  0.010  0.100  1.000   0.010   0.100   1.000    0.010    0.100    1.000\n",
       "score  0.869  0.884  0.884   0.883   0.884   0.884    0.884    0.884    0.884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS FOR rbf KERNEL\n",
      "\n",
      "Best parameters set found:\n",
      "{'C': 100, 'gamma': 0.01}\n",
      "Score with best parameters:\n",
      "0.9040000000000001\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2       3       4       5        6        7        8\n",
       "C      1.000  1.000  1.000  10.000  10.000  10.000  100.000  100.000  100.000\n",
       "gamma  0.010  0.100  1.000   0.010   0.100   1.000    0.010    0.100    1.000\n",
       "score  0.895  0.547  0.134   0.903   0.591   0.134    0.904    0.591    0.134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "\n",
    "#find best model uusing 5-fold CV \n",
    "#and train it using all the training data\n",
    "\n",
    "# ADD CODE\n",
    "linear_kernel = GridSearchCV(linear_SVM, parameters)\n",
    "\n",
    "linear_kernel.fit(X_train, y_train)\n",
    "\n",
    "print ('RESULTS FOR LINEAR KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD CODE\n",
    "print(linear_kernel.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD CODE\n",
    "print(linear_kernel.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD CODE\n",
    "#print(\"Mean test scores: \", linear_kernel.cv_results_['mean_test_score'])\n",
    "params = linear_kernel.cv_results_['params']\n",
    "scores = linear_kernel.cv_results_['mean_test_score']\n",
    "results = [{'C' : value['C'], 'score' : scores[index]} for index, value in enumerate(params)]\n",
    "display(pandas.DataFrame(results).T)\n",
    "\n",
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "poly2_SVM = SVC(kernel='poly',degree=2)\n",
    "\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR POLYNOMIAL KERNEL WITH DEGREE=2\n",
    "poly2_kernel = GridSearchCV(poly2_SVM, parameters)\n",
    "\n",
    "poly2_kernel.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR POLY DEGREE=2 KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD CODE\n",
    "print(poly2_kernel.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD CODE\n",
    "print(poly2_kernel.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD CODE\n",
    "#print(\"Mean test scores: \", poly2_kernel.cv_results_['mean_test_score'])\n",
    "params = poly2_kernel.cv_results_['params']\n",
    "scores = poly2_kernel.cv_results_['mean_test_score']\n",
    "results = [{'C' : value['C'], 'gamma' : value['gamma'], 'score' : scores[index]} for index, value in enumerate(params)]\n",
    "display(pandas.DataFrame(results).T)\n",
    "\n",
    "# parameters for rbf SVM\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR RBF KERNEL\n",
    "\n",
    "rbf_kernel = GridSearchCV(rbf_SVM, parameters)\n",
    "\n",
    "rbf_kernel.fit(X_train, y_train)\n",
    "\n",
    "print ('\\nRESULTS FOR rbf KERNEL\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "# ADD CODE\n",
    "print(rbf_kernel.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "# ADD CODE\n",
    "print(rbf_kernel.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "# ADD CODE\n",
    "#print(\"Mean test scores: \", rbf_kernel.cv_results_['mean_test_score'])\n",
    "params = rbf_kernel.cv_results_['params']\n",
    "scores = rbf_kernel.cv_results_['mean_test_score']\n",
    "results = [{'C' : value['C'], 'gamma' : value['gamma'], 'score' : scores[index]} for index, value in enumerate(params)]\n",
    "display(pandas.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training on the best SVM founded and computuing its errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM chosen: kernel=rbf, C=100, gamma=0.01\n",
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.080478\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "scores_SVM = [linear_kernel.best_score_, poly2_kernel.best_score_, rbf_kernel.best_score_]\n",
    "kernels_SVM = [linear_kernel, poly2_kernel, rbf_kernel]\n",
    "\n",
    "best = np.argmax(scores_SVM)\n",
    "params = kernels_SVM[best].best_estimator_.get_params()\n",
    "print(\"Best SVM chosen: \" +\n",
    "      \"kernel=\" + str(params['kernel']) + \n",
    "      \", C=\" + str(params['C']) +\n",
    "      \", gamma=\" + str(params[\"gamma\"]))\n",
    "\n",
    "best_SVM = kernels_SVM[best].best_estimator_ # ADD CODE\n",
    "\n",
    "# fit the model on the entire training set\n",
    "# ADD CODE\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "#get the training and test error\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use logistic regression for comparison\n",
    "\n",
    "Training model on regular logistic regression first and then with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Logistic Regression\n",
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.138116\n",
      "\n",
      "LR after 5-fold Cross Validation\n",
      "Best logistic regression training error: 0.003000\n",
      "Best logistic regression test error: 0.135362\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(max_iter=1000)\n",
    "# fit the model on the training data\n",
    "# ADD CODE\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#compute training and test error for model above\n",
    "training_error = 1 - lr.score(X_train, y_train) # COMPLETE\n",
    "test_error = 1 - lr.score(X_test, y_test) # COMPLETE\n",
    "print (\"Regular Logistic Regression\")\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)\n",
    "\n",
    "#logistic regression with 5-fold CV: you can use use linear_model.LogisticRegressionCV\n",
    "# use 5-fold CV to find the best choice of the parameter, than train\n",
    "# the model on the entire training set\n",
    "lr_cv = linear_model.LogisticRegressionCV(cv=5, max_iter=1000).fit(X_train, y_train) # COMPLETE\n",
    "training_error_cv = 1 - lr_cv.score(X_train, y_train) # COMPLETE\n",
    "test_error_cv = 1 - lr_cv.score(X_test, y_test) # COMPLETE\n",
    "\n",
    "print (\"\\nLR after 5-fold Cross Validation\")\n",
    "print (\"Best logistic regression training error: %f\" % training_error_cv)\n",
    "print (\"Best logistic regression test error: %f\" % test_error_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C obtained:  0.3593813663804626 \t[due to the default settings is the same for each class]\n"
     ]
    }
   ],
   "source": [
    "#line added to compare the regular LR with the LR trained with CV\n",
    "print(\"Best C obtained: \", lr_cv.C_[0], \"\\t[due to the default settings is the same for each class]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit missclassified by logistic regression and correctly classified by the \"best\" SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 4\n"
     ]
    }
   ],
   "source": [
    "# ADD CODE\n",
    "\n",
    "svm_labels = best_SVM.predict(X_test)\n",
    "lr_cv_labels = lr_cv.predict(X_test)\n",
    "for index, value in enumerate(y_test):\n",
    "    if (value != lr_cv_labels[index]) and (value == svm_labels[index]):\n",
    "        plot_digit(X_test, svm_labels, index)\n",
    "        plot_digit(X_test, lr_cv_labels, index)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "Compare and comment on the differences with the results above.\n",
    "\n",
    "#### ANSWER\n",
    "In terms of numerical results, they are improved by training the model with more samples and, as before, the **best error** on the overall experiment is obtained by the SVM with RBF kernel with a **test error** equals to **8%** and the final results of the linear regression models are quite similar to the SVM with linear kernel, with an error around 13% (as seen in the previous reasoning).\n",
    "\n",
    "However, with 1000 samples there are 2 main differences on the regularization parameter C:\n",
    "1. **SVM with RBF kernel:** C is increased by 100 times (C=10 with 500 samples, C=100 with 1000 samples), this give more weight to the empirical risk rather the hypoteshis complexity\n",
    "2. **LR_CV:** C is drastically decrease from 10000 to 0.36, this means that by training the model with more samples (they are doubled up) the empirical risk is nearly irrelevant and the hypotesis complexity has more importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
